{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training example\n",
    "Example of training a neural network model on chess dataset (with FEN formatting)."
   ],
   "id": "95522f9d7e0bbc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:10:05.471344Z",
     "start_time": "2025-04-13T16:10:03.409522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import os\n",
    "\n",
    "pl.seed_everything(100)\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from pretrain.utils.data import ChessDataModule\n",
    "from pretrain.utils.preprocess import FenDataset, LunaPreprocessing\n",
    "from luna.luna import Luna_Network\n",
    "from luna.game import ChessGame\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from typing import Dict\n",
    "from torch import nn, optim"
   ],
   "id": "90f65071b5543776",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 100\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:10:05.474690Z",
     "start_time": "2025-04-13T16:10:05.472235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_module = ChessDataModule(\n",
    "    data_dir='pretrain/data/out',\n",
    "    batch_size=1024,\n",
    "    num_workers=0,  # Don't use workers as it copies dataset and has os.chdir implications\n",
    "    schema=FenDataset.Schema,\n",
    "    preprocessing=[  # For e.g. FEN dataset preprocessing has to be done during batch creation\n",
    "        FenDataset(),  # Converts to standard and flexible dataset representation\n",
    "        LunaPreprocessing(use_mask=False),  # Converts to Luna sample\n",
    "    ],\n",
    "    transforms=[\n",
    "        # Here space for augmentation etc. Operates on results of preprocessing.\n",
    "    ],\n",
    ")"
   ],
   "id": "18d65c2f1df23f39",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:10:05.562321Z",
     "start_time": "2025-04-13T16:10:05.475479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = Luna_Network(\n",
    "    ChessGame()\n",
    ")\n",
    "net.nnet.init_weights()\n",
    "print(net.nnet)"
   ],
   "id": "9443fe15a69f1afb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LunaNN(\n",
      "  (conv1): Conv3d(1, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv2): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv3): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
      "  (conv5): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn4): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (fc_bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc_bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc_bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc4): Linear(in_features=512, out_features=4096, bias=True)\n",
      "  (fc5): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training info\n",
    "\n",
    "The model is trained with 4 losses. The policy, value, L2 and entropy. \n",
    "\n",
    "The policy loss is CrossEntropy\n",
    "between output policy and target label. The label is used instead of probability distribution as dataset\n",
    "move feedback is binary and in such way calculations are slightly faster.\n",
    "\n",
    "The value loss is Mean Squared Error Loss. Common approach.\n",
    "\n",
    "The L2 loss is to force the weights into following the normal distribution, in consequence making the model not \n",
    "exploit specific false patterns too much. Added to prevent overfitting.\n",
    "\n",
    "The entropy loss is taken from PPO (Proximal Policy Optimisation). It penalizes too low entropy of the model.\n",
    "It is here to ensure model, will not learn to always have minimal entropy in its predictions. In chess there\n",
    "is always more options than one correct move.\n",
    "\n"
   ],
   "id": "ef7219ec50edbab0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:10:05.568249Z",
     "start_time": "2025-04-13T16:10:05.563819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ExampleNetLightning(LightningModule):\n",
    "\n",
    "    def __init__(self, model: Luna_Network, l2_lambda: float, entropy_lambda: float):\n",
    "        super().__init__()\n",
    "        self.model = model.nnet\n",
    "        self.luna = model\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.entropy_lambda = entropy_lambda\n",
    "\n",
    "    def training_step(self, batch: Dict):\n",
    "        target_value, label = batch[\"value\"], batch[\"label\"]\n",
    "        boardAndValid =  batch[\"state\"], batch[\"mask\"]\n",
    "\n",
    "        policy, value = self.model(boardAndValid)\n",
    "        \n",
    "        # Standard loss\n",
    "        loss_policy = nn.functional.cross_entropy(policy.clone(), label,\n",
    "                                                  ignore_index=LunaPreprocessing.BAD_INDEX).mean()\n",
    "        loss_value = nn.functional.mse_loss(value.flatten(), target_value.flatten()).mean()\n",
    "        loss_l2 = self.l2_lambda * torch.mean(sum(torch.norm(param, 2) ** 2 for param in self.model.parameters()))\n",
    "\n",
    "        # Compliment on target distribution being binary (like in PPO)\n",
    "        loss_entropy = self.entropy_lambda * -torch.sum(policy.clone().detach().softmax(-1)\n",
    "                                                        * torch.log(policy.softmax(-1) + 1e-8), dim=-1)\n",
    "        loss_entropy[label == LunaPreprocessing.BAD_INDEX] = 0.0\n",
    "        loss_entropy = torch.mean(loss_entropy)\n",
    "        \n",
    "        loss = loss_policy + loss_value + loss_l2 + loss_entropy\n",
    "\n",
    "        self.log('train_loss_policy', loss_policy.clone(), on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_loss_value', loss_value.clone(), on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_loss', loss.clone(), on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_loss_entropy', loss_entropy.clone(), on_step=True, on_epoch=True)\n",
    "        self.log('train_loss_l2', loss_l2.clone(), on_step=True, on_epoch=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.model.parameters(), lr=0.001)"
   ],
   "id": "1ef3c603184bb396",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:10:05.570496Z",
     "start_time": "2025-04-13T16:10:05.568867Z"
    }
   },
   "cell_type": "code",
   "source": "model = ExampleNetLightning(net, l2_lambda=1e-4, entropy_lambda=1e-3)",
   "id": "1e09937a75200c63",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:10:05.592234Z",
     "start_time": "2025-04-13T16:10:05.571357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    logger=TensorBoardLogger(\n",
    "        save_dir=\"tensorboard\",\n",
    "        name=\"luna_training\",\n",
    "    ),\n",
    "    accelerator=\"gpu\",\n",
    ")"
   ],
   "id": "b3bf6053cf335407",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T16:36:51.047738Z",
     "start_time": "2025-04-13T16:10:05.592801Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.fit(model, data_module)",
   "id": "9f17a64021394471",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | LunaNN | 6.1 M  | train\n",
      "-----------------------------------------\n",
      "6.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "6.1 M     Total params\n",
      "24.435    Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/Users/fsociety/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60f848c6d2274d0fb336b34f2f3cfe19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:48\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     47\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:599\u001B[39m, in \u001B[36mTrainer._fit_impl\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    593\u001B[39m ckpt_path = \u001B[38;5;28mself\u001B[39m._checkpoint_connector._select_ckpt_path(\n\u001B[32m    594\u001B[39m     \u001B[38;5;28mself\u001B[39m.state.fn,\n\u001B[32m    595\u001B[39m     ckpt_path,\n\u001B[32m    596\u001B[39m     model_provided=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    597\u001B[39m     model_connected=\u001B[38;5;28mself\u001B[39m.lightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    598\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m599\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    601\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.state.stopped\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001B[39m, in \u001B[36mTrainer._run\u001B[39m\u001B[34m(self, model, ckpt_path)\u001B[39m\n\u001B[32m   1009\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m   1010\u001B[39m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[32m   1011\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1012\u001B[39m results = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1014\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m   1015\u001B[39m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[32m   1016\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001B[39m, in \u001B[36mTrainer._run_stage\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1055\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.autograd.set_detect_anomaly(\u001B[38;5;28mself\u001B[39m._detect_anomaly):\n\u001B[32m-> \u001B[39m\u001B[32m1056\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit_loop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1057\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001B[39m, in \u001B[36m_FitLoop.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28mself\u001B[39m.on_advance_start()\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[38;5;28mself\u001B[39m.on_advance_end()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001B[39m, in \u001B[36m_FitLoop.advance\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    454\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m._data_fetcher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m455\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mepoch_loop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:150\u001B[39m, in \u001B[36m_TrainingEpochLoop.run\u001B[39m\u001B[34m(self, data_fetcher)\u001B[39m\n\u001B[32m    149\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    151\u001B[39m     \u001B[38;5;28mself\u001B[39m.on_advance_end(data_fetcher)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:339\u001B[39m, in \u001B[36m_TrainingEpochLoop.advance\u001B[39m\u001B[34m(self, data_fetcher)\u001B[39m\n\u001B[32m    337\u001B[39m     \u001B[38;5;28mself\u001B[39m.batch_progress.is_last_batch = data_fetcher.done\n\u001B[32m--> \u001B[39m\u001B[32m339\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_callback_hooks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mon_train_batch_end\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    340\u001B[39m call._call_lightning_module_hook(trainer, \u001B[33m\"\u001B[39m\u001B[33mon_train_batch_end\u001B[39m\u001B[33m\"\u001B[39m, batch_output, batch, batch_idx)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:227\u001B[39m, in \u001B[36m_call_callback_hooks\u001B[39m\u001B[34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001B[39m\n\u001B[32m    226\u001B[39m         \u001B[38;5;28;01mwith\u001B[39;00m trainer.profiler.profile(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[Callback]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcallback.state_key\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m227\u001B[39m             \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlightning_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    229\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m pl_module:\n\u001B[32m    230\u001B[39m     \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py:279\u001B[39m, in \u001B[36mTQDMProgressBar.on_train_batch_end\u001B[39m\u001B[34m(self, trainer, pl_module, outputs, batch, batch_idx)\u001B[39m\n\u001B[32m    278\u001B[39m _update_n(\u001B[38;5;28mself\u001B[39m.train_progress_bar, n)\n\u001B[32m--> \u001B[39m\u001B[32m279\u001B[39m \u001B[38;5;28mself\u001B[39m.train_progress_bar.set_postfix(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpl_module\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/progress/progress_bar.py:198\u001B[39m, in \u001B[36mProgressBar.get_metrics\u001B[39m\u001B[34m(self, trainer, pl_module)\u001B[39m\n\u001B[32m    197\u001B[39m standard_metrics = get_standard_metrics(trainer)\n\u001B[32m--> \u001B[39m\u001B[32m198\u001B[39m pbar_metrics = \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprogress_bar_metrics\u001B[49m\n\u001B[32m    199\u001B[39m duplicates = \u001B[38;5;28mlist\u001B[39m(standard_metrics.keys() & pbar_metrics.keys())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1667\u001B[39m, in \u001B[36mTrainer.progress_bar_metrics\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1661\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"The metrics sent to the progress bar.\u001B[39;00m\n\u001B[32m   1662\u001B[39m \n\u001B[32m   1663\u001B[39m \u001B[33;03mThis includes metrics logged via :meth:`~pytorch_lightning.core.LightningModule.log` with the\u001B[39;00m\n\u001B[32m   1664\u001B[39m \u001B[33;03m:paramref:`~pytorch_lightning.core.LightningModule.log.prog_bar` argument set.\u001B[39;00m\n\u001B[32m   1665\u001B[39m \n\u001B[32m   1666\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1667\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_logger_connector\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprogress_bar_metrics\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:254\u001B[39m, in \u001B[36m_LoggerConnector.progress_bar_metrics\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    253\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.trainer._results:\n\u001B[32m--> \u001B[39m\u001B[32m254\u001B[39m     metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmetrics\u001B[49m[\u001B[33m\"\u001B[39m\u001B[33mpbar\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    255\u001B[39m     \u001B[38;5;28mself\u001B[39m._progress_bar_metrics.update(metrics)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:235\u001B[39m, in \u001B[36m_LoggerConnector.metrics\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    234\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.trainer._results \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m235\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_results\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mon_step\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:493\u001B[39m, in \u001B[36m_ResultCollection.metrics\u001B[39m\u001B[34m(self, on_step)\u001B[39m\n\u001B[32m    492\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m result_metric.meta.prog_bar:\n\u001B[32m--> \u001B[39m\u001B[32m493\u001B[39m         metrics[\u001B[33m\"\u001B[39m\u001B[33mpbar\u001B[39m\u001B[33m\"\u001B[39m][forked_name] = \u001B[43mconvert_tensors_to_scalars\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    495\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m metrics\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/lightning_fabric/utilities/apply_func.py:136\u001B[39m, in \u001B[36mconvert_tensors_to_scalars\u001B[39m\u001B[34m(data)\u001B[39m\n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m value.item()\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mapply_to_collection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_item\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/lightning_utilities/core/apply_func.py:66\u001B[39m, in \u001B[36mapply_to_collection\u001B[39m\u001B[34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001B[39m\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, dtype):  \u001B[38;5;66;03m# single element\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m data.\u001B[34m__class__\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28mlist\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, dtype) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m data):  \u001B[38;5;66;03m# 1d homogeneous list\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/lightning_fabric/utilities/apply_func.py:134\u001B[39m, in \u001B[36mconvert_tensors_to_scalars.<locals>.to_item\u001B[39m\u001B[34m(value)\u001B[39m\n\u001B[32m    131\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    132\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThe metric `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m` does not contain a single element, thus it cannot be converted to a scalar.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    133\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mvalue\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_module\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:561\u001B[39m, in \u001B[36mTrainer.fit\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    559\u001B[39m \u001B[38;5;28mself\u001B[39m.training = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    560\u001B[39m \u001B[38;5;28mself\u001B[39m.should_stop = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m561\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    562\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[32m    563\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Programing/PyCharm/ChessRL/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:65\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     63\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(launcher, _SubprocessScriptLauncher):\n\u001B[32m     64\u001B[39m         launcher.kill(_get_sigkill_signal())\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m     \u001B[43mexit\u001B[49m(\u001B[32m1\u001B[39m)\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[32m     68\u001B[39m     _interrupt(trainer, exception)\n",
      "\u001B[31mNameError\u001B[39m: name 'exit' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(model, \"lightning_model.pt\")",
   "id": "f7bc7f984892c72c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "34c507223bca8853",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
